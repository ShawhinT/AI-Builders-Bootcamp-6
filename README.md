# AI-Builders-Bootcamp-6
Code repository for AI Builders Bootcamp #6

Past Cohorts: [Cohort 1](https://github.com/ShawhinT/AI-Builders-Bootcamp-1) | [Cohort 2](https://github.com/ShawhinT/AI-Builders-Bootcamp-2) | [Cohort 3](https://github.com/ShawhinT/AI-Builders-Bootcamp-3) | [Cohort 4](https://github.com/ShawhinT/AI-Builders-Bootcamp-4) | [Cohort 5](https://github.com/ShawhinT/AI-Builders-Bootcamp-5)

Course homepage on Maven: https://maven.com/shaw-talebi/ai-builders-bootcamp

## Session 1: Introduction, Software 1.0
Getting started with AI and building with LLM-powered tools.

Examples:
- [Scraping AI job board](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-1/example_1-scrape_job_board.ipynb)
- [Vibe Coding Data Dashboard](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-1/example_2-job_dashboard.py)

## Session 2: LLMs, Prompt Engineering
Here, we begin building AI systems with LLMs. Unlike machine learning, we don't need datasets to get started.

Examples:
- [Research paper summarizer](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-2/example_1-paper_summarizer.ipynb)
- [Text classifier](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-2/example_2-text-classifier.ipynb)
- [Local visual QA with LLaMA 3.2 Vision](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-2/example_3-local_visual_QA.ipynb)

## Session 3: RAG, Text Embeddings
Prompting LLMs ChatGPT-style only scratches the surface of what we can use modern language models for. We can also leverage RAG to improve model performance and text embeddings to make text computable.

Examples:
- [Analyzing Unstructured Survey Data](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-3/example_1-unstructured_survey_analysis.ipynb)
- [RAG with LlamaIndex](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-3/example_2-rag_with_llamaindex.ipynb)
- [PDF Parsing with Docling](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-3/example_3-pdf_parsing_docling.ipynb)

## Session 4: Tool Use, AI Agents
While prompting LLMs and automatically giving them relevant context can take us far, they still involve a traditional approach to software development. Namely, developers break down tasks into steps and translate them into code + LLM calls. 

Agents present a new way of thinking about software. Rather than explicitly defining rules and business logic, agents involve giving LLMs the tools they need to solve problems.
- [YouTube Agent](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-4/example_1-youtube_agent.ipynb)
- [Notion MCP Agent](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-4/example_2-notion_mcp_agent.ipynb)
- [Upwork Profile Rewriter (in a loop)](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-4/example_3-profile_rewriter_loop.ipynb)

## Session 5: Fine-tuning
Although LLMs can solve a wide range of problems out of the box, there are situations where more model customization is required. This can be achieved through model fine-tuning, which involves adapting a model to a particular use case through additional training.

Examples
- [Fine-tuning a LinkedIn Post Writer](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-5/example_1-linkedin_post_writer.ipynb)
- [Fine-tuning BERT for Text Classification](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-5/example_2-finetune_bert_classifier.ipynb)

## Session 6: Deploying AI Apps
Building projects is one of the best ways to learn AI. However, if your projects only live on your laptop, the value your software generates will always be limited. This example shows a simple way to deploy AI apps (for free) using Docker and Hugging Face Spaces.

Example
- [Hosting a YouTube Agent](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/tree/main/session-6)
